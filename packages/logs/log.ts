import { Logtail } from '@logtail/node';
import { config, env } from '@repo/config';
import pino from 'pino';
import {
  GlobalContextStorageProvider,
  lambdaRequestTracker,
  pinoLambdaDestination,
} from 'pino-lambda';
import pretty from 'pino-pretty';

// ---------- DESTINATIONS ----------
/** Create Logtail client if we're in deployment (and we enabled it) */
const logtail = env.BETTER_STACK_SOURCE_TOKEN
  ? new Logtail(env.BETTER_STACK_SOURCE_TOKEN, {
      endpoint: env.BETTER_STACK_INGESTING_URL,
    })
  : undefined;
/** Our lambda destination (ensures things are formatted for cloudwatch) */
const lambdaDest = pinoLambdaDestination();
/** Our pretty destination (ensures things are formatted for the console) */
const prettyDest = pretty({
  colorize: true,
  translateTime: 'SYS:HH:mm:ss',
  ignore: 'env,userId,awsRequestId,apiRequestId,x-correlation-id',
});

// ---------- HELPERS ----------
/** Adds lambda request context to the current request context */
export const addLambdaRequestContext = lambdaRequestTracker();

/** Gets the current request context */
export const getLogMetadata = () => {
  return GlobalContextStorageProvider.getContext();
};

/** Adds metadata to the current request context */
export const addLogMetadata = (metadata: Record<string, unknown>) => {
  GlobalContextStorageProvider.updateContext(metadata);
};

/** Flushes the logs to ensure they're sent to our destinations */
export const flushLogs = async () => {
  try {
    if (logtail) await logtail.flush();
  } catch (error) {
    console.error('[log] Failed to flush logs:', error);
  }
};

/** The message format generated by pino */
type PinoLog = {
  level: string;
  msg: string;
  [key: string]: unknown;
};

// ---------- PINO ----------
/** Create a custom destination that handles all our destinations */
const customDestination = {
  write: async (payload: string) => {
    try {
      // If we're running in a deployment, we should handle production logs
      if (config.isDeployment) {
        // Format logs the way cloudwatch needs
        lambdaDest.write(payload);
        // Also send logs to Better Stack
        if (logtail) {
          // Format the payload to be the way logtail expects it
          const { level, msg, ...context } = JSON.parse(payload) as PinoLog;
          if (level) await logtail.log(msg, level, context);
        }
      }
      // If we're running locally, show the pretty output
      else prettyDest.write(payload);
    } catch (error) {
      console.error('[log] Failed to handle log:', error);
    }
  },
};

// Create our logging instance
export const log = pino(
  {
    // Ensure we handle levels the way that Better Stack expects
    level: process.env.LOG_LEVEL || 'info',
    formatters: {
      level: (label) => ({ level: label }),
    },
    // Attach any global context variables
    base: {
      env: config.stage,
    },
    // Add our AWS context into our logs
    mixin: () => getLogMetadata(),
  },
  customDestination
);
