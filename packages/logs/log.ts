import { AsyncLocalStorage } from 'node:async_hooks';
import { Axiom } from '@axiomhq/js';
import { config } from '@repo/config';
import pino from 'pino';
import pretty from 'pino-pretty';

// ---------- CONTEXT STORAGE ----------
/** AsyncLocalStorage for request-scoped context */
const contextStorage = new AsyncLocalStorage<Record<string, unknown>>();

// ---------- DESTINATIONS ----------
/** Our axiom client */
const axiom = process.env.AXIOM_TOKEN
  ? new Axiom({
      token: process.env.AXIOM_TOKEN,
    })
  : undefined;

/** Our pretty destination (ensures things are formatted for the console) */
const prettyDest = pretty({
  colorize: true,
  translateTime: 'SYS:HH:mm:ss',
  // Ignore some params that we don't care about locally
  ignore: 'env,userId,request,langfuseTraceId,requestId',
});

// ---------- HELPERS ----------
/**
 * Wraps a function to provide access to a logging context that allows you to include
 * various metadata in all of your logs (like sharing a requestId on logs).
 */
export const withLoggingContext = <T>(
  metadata: Record<string, unknown>,
  fn: () => T
): T => contextStorage.run({ ...metadata }, fn);

type LogMetadata = {
  langfuseTraceId?: string;
  userId?: string;
  requestId?: string;
  request?: { method?: string; path?: string };
};

/** Gets the current request context */
export const getLogMetadata = (): LogMetadata =>
  (contextStorage.getStore() ?? {}) as LogMetadata;

/** Adds metadata to the current request context */
export const addLogMetadata = (metadata: Record<string, unknown>) => {
  const store = contextStorage.getStore();
  if (store) {
    Object.assign(store, metadata);
  }
};

/** Ensures all logs are flushed */
export const flushLogs = async () => {
  try {
    if (axiom) {
      await axiom.flush();
    }
  } catch (error) {
    console.error('[log] Failed to flush logs:', error);
  }
};

/** The message format generated by pino */
type PinoLog = {
  level: string;
  msg: string;
  [key: string]: unknown;
};

// ---------- PINO ----------
/** Create a custom destination that handles all our destinations */
const customDestination = {
  write: (payload: string) => {
    try {
      // If we're running locally, show the pretty output
      if (config.isLocal) {
        prettyDest.write(payload);
      }
      // If we're running in a deployed environment, we need to do a few things
      else {
        // Write to stdout for Vercel's log streaming
        process.stdout.write(`${payload}\n`);

        // Also send logs to Axiom for better log management (if configured)
        if (axiom) {
          // Format the payload to be the way axiom expects it
          const { time, level, msg, ...context } = JSON.parse(
            payload
          ) as PinoLog;
          axiom.ingest(process.env.AXIOM_DATASET ?? '', [
            {
              // Axiom-specific fields (we have to include level twice or it doesn't work right)
              _time: time,
              level,
              severity: level,
              message: msg,
              // Remaining context
              ...context,
            },
          ]);
        }
      }
    } catch (error) {
      console.error('[log] Failed to handle log:', error);
    }
  },
};

// Create our logging instance
export const log = pino(
  {
    level: process.env.LOG_LEVEL || 'info',
    formatters: {
      level: (label) => ({ level: label }),
    },
    // Attach any global context variables
    base: {
      env: config.env,
    },
    // Add any additional global context into our logs
    mixin: () => getLogMetadata(),
  },
  customDestination
);
